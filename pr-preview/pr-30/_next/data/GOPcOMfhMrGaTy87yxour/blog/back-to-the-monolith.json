{"pageProps":{"post":{"content":"\n\n### Amazon embraces the mighty monolith\n\n<img src=\"/images/step-functions.webp\" alt=\"image alt text\" style=\"width: 50%; float: left; padding: 5px;\" />\n\nAmazon published a [blog post](https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90)\non March 2023, detailing how they had managed to reduce the cost of their audio-video monitoring service by 90%.\nThe _key_ to this reduction was to migrate from a distributed, microservice architecture to a _monolith_.\nThe blog post went viral and triggered some software celebrities to \n[question](https://world.hey.com/dhh/even-amazon-can-t-make-sense-of-serverless-or-microservices-59625580) the entire concept of microservices.\n\n### What should we learn from this?\n\nSo, are microservices a flawed concept? Should we all migrate back to monoliths?\n_No_ and _definitely no_ I would say. Instead, my takeaways from this article are:\n\n1.  **Microservices aren't about scaling for performance.** At least not primarily. Although the possibility to horizontally scale \ncomputationally intensive operations _can_ be very useful or even essential in some cases, I've found it to be \nquite a rare benefit. Very often performance bottlenecks are IO bound or outside your sphere of influence.\nBut, there are other reasons for  considering microservices: they _force_ you to communicate via contracts, _encourage_ you to organize your functionality around domains,\nand _allow_ you to scale your organization. Of course, all this comes at considerable costs. There's no [free lunch üëá](#presentation).\n2.  <iframe width=\"320\" height=\"200\" src=\"https://www.youtube.com/embed/HysU3E7Ilm8\" frameborder=\"0\" style=\"float: right; padding: 5px;\"></iframe> <b>Don't underestimate the power of a single CPU in 2023</b>. To judge whether a process is unreasonably slow or not, I tend to think of the fact that the in the nineties, screens showed 65K pixels at any one time. Back then, it was possible to perform multiple arithmetic calculations (additions, subtractions) for each pixel, a hundred times per second. Nowadays, your screen probably displays more than 5 Million pixels at once. So, if the amount of datapoints you are dealing with in the order of millions, you should generally be able to process them in a matter of seconds on a single machine. If you can't, you're likely doing something <i>very</i> inefficient.\n3.  **Software engineering is hard**. Mistakes are made all the time, everywhere. Even at the big 4. Kudos to Amazon üëè for sharing their mistake they made so that we may all learn.\nSpeaking of which, here's one of our own:\n\n### The cost of distribution: a case in point\n\nFor any utility company it is essential accurately to predict both the consumption and production of electricity.\nFailing to do so can result in blackouts or overproduction, both of which are [very costly](https://vandebron.nl/blog/hoe-houdt-onze-technologie-het-energienet-in-balans).\nVandebron is a unique utility company in that the electricity that our customers consume is produced by a [very large\namount](https://vandebron.nl/energiebronnen) of relatively small scale producers, who produce electricity using windmills or solar panels.\nThe large number and the weather dependent nature of these producers makes it very hard to predict how much electricity will be produced at any given time.\n\nTo do this, we use a machine learning model that is trained on historical production data \nand predictions from the national weather [institute](https://www.knmi.nl/). As you can imagine, this is a computationally intensive task, involving large amounts of data.\nFortunately, we have [tooling in place](https://www.vandebron.tech/blog/fueling-the-energy-transition-with-spark-part-1) that\nallows us to distribute computations of a cluster of machines if the task is too large for a single machine to handle.\n\nHere's the catch: the fact that we _can_ distribute computations does not mean that we should. Initially it seemed that\nwe couldn't analyze the weather data quick enough for the estimation of our production to still be a prediction\nrather than a postdiction. We decided to distribute the computation of the weather data over a cluster of machines.\nThis worked, but it made our software more complex and Jeff Bezos even richer than he already was.\n\nOn close inspection, we found an extreme inefficiency in our code. It turned out that the entire weather dataset was\nread into memory again, for _every_ single \"pixel\" in it. After removing this performance bug, the entire analysis could _easily_ be done\non a single machine. \n\n### What else?\n\n<a id=\"presentation\"> </a>\n\nAt [Vandebron](https://vandebron.nl/), we have jumped onto the Microservice bandwagon circa 2019. Even though this decision wasn't made on a whim, \nwe've still ended up making many mistakes / learning a lot. In this presentation to students of\n[VU University Amsterdam](https://vu.nl/) I share some of our most important learnings.\n[![Presentation about micro services to students of VU Amsterdam](/images/play_presentation.webp)](https://youtu.be/HDs-pCsEzKM)\n\n\n","meta":{"title":"So, back to the monolith it is then?","description":"A recent Amazon article explaining how they managed to save costs by merging some of their services has lead some to question the value of microservices. What is our take?","createdAt":"Sat May 20 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","coverImage":"images/monolith.webp","tags":"dagster, cicd, ci-cd, orchestration, data pipeline, kubernetes, migration, helm, ansible","author":"Sam Theisens","slug":"blog/back-to-the-monolith","formattedDate":"20 mei 2023","date":"Sat May 20 2023 00:00:00 GMT+0000 (Coordinated Universal Time)"}}},"__N_SSG":true}